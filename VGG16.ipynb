{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iUGCkcKmYItU"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "%matplotlib inline \n",
    "from tensorflow import keras\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten ,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam,Nadam, SGD\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EZpxu855d4E3"
   },
   "outputs": [],
   "source": [
    "cats=[]\n",
    "i=0\n",
    "for images in os.listdir('cats'):\n",
    "    img=cv2.imread((\"cats//\" +images),cv2.IMREAD_UNCHANGED)\n",
    "    if(type(img) == type(None)):\n",
    "      pass\n",
    "    else:\n",
    "      resized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\n",
    "      normalize=(np.asarray(resized).astype('float32')) / 255\n",
    "      cats.append(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "si5nJncfd85F"
   },
   "outputs": [],
   "source": [
    "dogs=[]\n",
    "i=0\n",
    "for images in os.listdir('dogs'):\n",
    "    img=cv2.imread((\"dogs//\" +images),cv2.IMREAD_UNCHANGED)\n",
    "    if(type(img) == type(None)):\n",
    "      pass\n",
    "    else:\n",
    "      resized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\n",
    "      normalize=(np.asarray(resized).astype('float32')) / 255\n",
    "      dogs.append(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "j--3x2pBeAbL"
   },
   "outputs": [],
   "source": [
    "data = cats+dogs\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XopOXHNAlN3H",
    "outputId": "86ad66fb-d6db-4d5f-b63b-7c36968df8ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1995, 224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZXbfbApseB05"
   },
   "outputs": [],
   "source": [
    "cats_labels = np.ones(len(cats))\n",
    "dogs_labels = np.zeros(len(dogs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIpEYWc7khXH",
    "outputId": "b230b512-2fc3-40c6-8058-2ae5f2a07fbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.concatenate((cats_labels, dogs_labels))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "M8JVLQ9FgOAJ"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data,labels,shuffle=True,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3g1PTbZxm72J",
    "outputId": "d31e8425-49c2-4049-f1ca-45a835deca93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3E_fzEMnSZA",
    "outputId": "6c04a695-bbdd-43c7-90c3-a38103057398"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "M3A7Mf3KgV57"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Qp-iCgZIsmLj"
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbTdvtvEgWD-",
    "outputId": "4e817627-be38-4512-f59d-ab78078aafcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 224, 224, 64)     256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 112, 112, 128)    512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 56, 56, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 28, 28, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 14, 14, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 8194      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,274,626\n",
      "Trainable params: 134,271,682\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.optimizers.SGD(lr=0.01),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rB68mgaSgwec",
    "outputId": "e196c505-8173-4b64-bad6-a0862b7b8210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "57/57 [==============================] - 54s 711ms/step - loss: 1.8512 - accuracy: 0.5471 - val_loss: 0.9187 - val_accuracy: 0.4700\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 28s 497ms/step - loss: 0.6457 - accuracy: 0.6474 - val_loss: 0.7894 - val_accuracy: 0.4700\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 29s 503ms/step - loss: 0.5573 - accuracy: 0.7220 - val_loss: 0.8733 - val_accuracy: 0.5300\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 29s 502ms/step - loss: 0.4741 - accuracy: 0.7705 - val_loss: 0.8244 - val_accuracy: 0.5200\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 28s 498ms/step - loss: 0.3837 - accuracy: 0.8329 - val_loss: 0.8496 - val_accuracy: 0.4650\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 28s 500ms/step - loss: 0.2785 - accuracy: 0.8986 - val_loss: 0.8437 - val_accuracy: 0.5550\n",
      "Epoch 7/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.2047 - accuracy: 0.9331 - val_loss: 4.5995 - val_accuracy: 0.5300\n",
      "Epoch 8/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.4235 - accuracy: 0.8373 - val_loss: 0.9337 - val_accuracy: 0.5800\n",
      "Epoch 9/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.2148 - accuracy: 0.9287 - val_loss: 0.8778 - val_accuracy: 0.6500\n",
      "Epoch 10/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0911 - accuracy: 0.9822 - val_loss: 1.3422 - val_accuracy: 0.6150\n",
      "Epoch 11/100\n",
      "57/57 [==============================] - 28s 498ms/step - loss: 0.1790 - accuracy: 0.9515 - val_loss: 2.2133 - val_accuracy: 0.5400\n",
      "Epoch 12/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.1462 - accuracy: 0.9554 - val_loss: 0.8839 - val_accuracy: 0.6600\n",
      "Epoch 13/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0330 - accuracy: 0.9989 - val_loss: 0.8755 - val_accuracy: 0.6800\n",
      "Epoch 14/100\n",
      "57/57 [==============================] - 28s 498ms/step - loss: 0.0176 - accuracy: 0.9994 - val_loss: 0.8818 - val_accuracy: 0.6750\n",
      "Epoch 15/100\n",
      "57/57 [==============================] - 29s 500ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.8617 - val_accuracy: 0.6950\n",
      "Epoch 16/100\n",
      "57/57 [==============================] - 28s 500ms/step - loss: 0.0109 - accuracy: 0.9989 - val_loss: 0.9877 - val_accuracy: 0.6550\n",
      "Epoch 17/100\n",
      "57/57 [==============================] - 28s 500ms/step - loss: 0.0085 - accuracy: 0.9994 - val_loss: 0.9244 - val_accuracy: 0.6800\n",
      "Epoch 18/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.0020 - val_accuracy: 0.6750\n",
      "Epoch 19/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.3519 - val_accuracy: 0.6000\n",
      "Epoch 20/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.0088 - accuracy: 0.9994 - val_loss: 7.7738 - val_accuracy: 0.4750\n",
      "Epoch 21/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.1717 - accuracy: 0.9621 - val_loss: 0.8334 - val_accuracy: 0.6800\n",
      "Epoch 22/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.8751 - val_accuracy: 0.6800\n",
      "Epoch 23/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.9546 - val_accuracy: 0.6750\n",
      "Epoch 24/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 16.3384 - val_accuracy: 0.5300\n",
      "Epoch 25/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.3061 - accuracy: 0.9292 - val_loss: 1.5199 - val_accuracy: 0.5350\n",
      "Epoch 26/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.0429 - accuracy: 0.9911 - val_loss: 0.9225 - val_accuracy: 0.6500\n",
      "Epoch 27/100\n",
      "57/57 [==============================] - 28s 500ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.0365 - val_accuracy: 0.6300\n",
      "Epoch 28/100\n",
      "57/57 [==============================] - 28s 498ms/step - loss: 0.0090 - accuracy: 0.9994 - val_loss: 3.6032 - val_accuracy: 0.5100\n",
      "Epoch 29/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0564 - accuracy: 0.9866 - val_loss: 0.9768 - val_accuracy: 0.6500\n",
      "Epoch 30/100\n",
      "57/57 [==============================] - 29s 506ms/step - loss: 0.0084 - accuracy: 0.9994 - val_loss: 0.9656 - val_accuracy: 0.6600\n",
      "Epoch 31/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0419 - val_accuracy: 0.6700\n",
      "Epoch 32/100\n",
      "57/57 [==============================] - 29s 500ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1743 - val_accuracy: 0.6400\n",
      "Epoch 33/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.0605 - val_accuracy: 0.6750\n",
      "Epoch 34/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0983 - val_accuracy: 0.6750\n",
      "Epoch 35/100\n",
      "57/57 [==============================] - 28s 500ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0719 - val_accuracy: 0.6800\n",
      "Epoch 36/100\n",
      "57/57 [==============================] - 28s 500ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.2839 - val_accuracy: 0.5350\n",
      "Epoch 37/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 1.1869 - val_accuracy: 0.6200\n",
      "Epoch 38/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1109 - val_accuracy: 0.6450\n",
      "Epoch 39/100\n",
      "57/57 [==============================] - 29s 500ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.1449 - val_accuracy: 0.6800\n",
      "Epoch 40/100\n",
      "57/57 [==============================] - 29s 500ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1582 - val_accuracy: 0.6700\n",
      "Epoch 41/100\n",
      "57/57 [==============================] - 28s 500ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 32.5768 - val_accuracy: 0.4700\n",
      "Epoch 42/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.5036 - accuracy: 0.8613 - val_loss: 3.6966 - val_accuracy: 0.5650\n",
      "Epoch 43/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0913 - accuracy: 0.9794 - val_loss: 0.9610 - val_accuracy: 0.6200\n",
      "Epoch 44/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0162 - accuracy: 0.9994 - val_loss: 0.9335 - val_accuracy: 0.6650\n",
      "Epoch 45/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0086 - accuracy: 0.9994 - val_loss: 2.3808 - val_accuracy: 0.5350\n",
      "Epoch 46/100\n",
      "57/57 [==============================] - 29s 500ms/step - loss: 0.0848 - accuracy: 0.9760 - val_loss: 1.1197 - val_accuracy: 0.6450\n",
      "Epoch 47/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.9758 - val_accuracy: 0.6650\n",
      "Epoch 48/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9990 - val_accuracy: 0.6850\n",
      "Epoch 49/100\n",
      "57/57 [==============================] - 29s 500ms/step - loss: 0.0079 - accuracy: 0.9994 - val_loss: 16.8574 - val_accuracy: 0.5450\n",
      "Epoch 50/100\n",
      "57/57 [==============================] - 29s 507ms/step - loss: 0.2908 - accuracy: 0.9370 - val_loss: 1.4172 - val_accuracy: 0.5950\n",
      "Epoch 51/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0214 - accuracy: 0.9983 - val_loss: 0.9913 - val_accuracy: 0.6500\n",
      "Epoch 52/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.9536 - val_accuracy: 0.6550\n",
      "Epoch 53/100\n",
      "57/57 [==============================] - 28s 500ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0283 - val_accuracy: 0.6700\n",
      "Epoch 54/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.0876 - val_accuracy: 0.6600\n",
      "Epoch 55/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 1.2302 - val_accuracy: 0.6300\n",
      "Epoch 56/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.8995 - val_accuracy: 0.5600\n",
      "Epoch 57/100\n",
      "57/57 [==============================] - 28s 500ms/step - loss: 0.0193 - accuracy: 0.9928 - val_loss: 1.0856 - val_accuracy: 0.6800\n",
      "Epoch 58/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.8336 - val_accuracy: 0.5900\n",
      "Epoch 59/100\n",
      "57/57 [==============================] - 29s 500ms/step - loss: 0.0126 - accuracy: 0.9978 - val_loss: 1.0639 - val_accuracy: 0.6650\n",
      "Epoch 60/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1082 - val_accuracy: 0.6600\n",
      "Epoch 61/100\n",
      "57/57 [==============================] - 28s 500ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.1772 - val_accuracy: 0.5750\n",
      "Epoch 62/100\n",
      "57/57 [==============================] - 28s 498ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 1.1759 - val_accuracy: 0.6500\n",
      "Epoch 63/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3252 - val_accuracy: 0.6550\n",
      "Epoch 64/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 3.7487 - val_accuracy: 0.5700\n",
      "Epoch 65/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0829 - accuracy: 0.9777 - val_loss: 1.1031 - val_accuracy: 0.7050\n",
      "Epoch 66/100\n",
      "57/57 [==============================] - 28s 500ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4826 - val_accuracy: 0.6350\n",
      "Epoch 67/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 2.2331 - val_accuracy: 0.5850\n",
      "Epoch 68/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.0151 - accuracy: 0.9972 - val_loss: 1.1639 - val_accuracy: 0.6750\n",
      "Epoch 69/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1251 - val_accuracy: 0.7000\n",
      "Epoch 70/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1511 - val_accuracy: 0.6950\n",
      "Epoch 71/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3116 - val_accuracy: 0.6850\n",
      "Epoch 72/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.2959 - val_accuracy: 0.6800\n",
      "Epoch 73/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2190 - val_accuracy: 0.6950\n",
      "Epoch 74/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.1914 - val_accuracy: 0.7000\n",
      "Epoch 75/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2454 - val_accuracy: 0.6900\n",
      "Epoch 76/100\n",
      "57/57 [==============================] - 28s 500ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2332 - val_accuracy: 0.6900\n",
      "Epoch 77/100\n",
      "57/57 [==============================] - 28s 498ms/step - loss: 8.9663e-04 - accuracy: 1.0000 - val_loss: 1.2106 - val_accuracy: 0.7050\n",
      "Epoch 78/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 7.5800e-04 - accuracy: 1.0000 - val_loss: 1.2306 - val_accuracy: 0.7000\n",
      "Epoch 79/100\n",
      "57/57 [==============================] - 29s 502ms/step - loss: 7.4805e-04 - accuracy: 1.0000 - val_loss: 1.2348 - val_accuracy: 0.6950\n",
      "Epoch 80/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 6.3910e-04 - accuracy: 1.0000 - val_loss: 1.4236 - val_accuracy: 0.6550\n",
      "Epoch 81/100\n",
      "57/57 [==============================] - 28s 498ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.3822 - val_accuracy: 0.5300\n",
      "Epoch 82/100\n",
      "57/57 [==============================] - 29s 500ms/step - loss: 0.0284 - accuracy: 0.9950 - val_loss: 1.2382 - val_accuracy: 0.6650\n",
      "Epoch 83/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 1.2407 - val_accuracy: 0.6700\n",
      "Epoch 84/100\n",
      "57/57 [==============================] - 28s 498ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.1566 - val_accuracy: 0.6800\n",
      "Epoch 85/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1786 - val_accuracy: 0.6950\n",
      "Epoch 86/100\n",
      "57/57 [==============================] - 28s 498ms/step - loss: 9.5854e-04 - accuracy: 1.0000 - val_loss: 1.1655 - val_accuracy: 0.6950\n",
      "Epoch 87/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 9.5336e-04 - accuracy: 1.0000 - val_loss: 1.1975 - val_accuracy: 0.6950\n",
      "Epoch 88/100\n",
      "57/57 [==============================] - 29s 500ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.0413 - val_accuracy: 0.6050\n",
      "Epoch 89/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0094 - accuracy: 0.9961 - val_loss: 87.5936 - val_accuracy: 0.4700\n",
      "Epoch 90/100\n",
      "57/57 [==============================] - 29s 502ms/step - loss: 0.5703 - accuracy: 0.8329 - val_loss: 1.5553 - val_accuracy: 0.5450\n",
      "Epoch 91/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0688 - accuracy: 0.9827 - val_loss: 0.9049 - val_accuracy: 0.6400\n",
      "Epoch 92/100\n",
      "57/57 [==============================] - 28s 500ms/step - loss: 0.0130 - accuracy: 0.9994 - val_loss: 0.9590 - val_accuracy: 0.6600\n",
      "Epoch 93/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0080 - accuracy: 0.9994 - val_loss: 0.9424 - val_accuracy: 0.6700\n",
      "Epoch 94/100\n",
      "57/57 [==============================] - 28s 498ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.9821 - val_accuracy: 0.6750\n",
      "Epoch 95/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.6056 - val_accuracy: 0.6100\n",
      "Epoch 96/100\n",
      "57/57 [==============================] - 29s 500ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 1.0242 - val_accuracy: 0.6550\n",
      "Epoch 97/100\n",
      "57/57 [==============================] - 28s 498ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0470 - val_accuracy: 0.6700\n",
      "Epoch 98/100\n",
      "57/57 [==============================] - 28s 500ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 2.7613 - val_accuracy: 0.6050\n",
      "Epoch 99/100\n",
      "57/57 [==============================] - 28s 500ms/step - loss: 0.0289 - accuracy: 0.9933 - val_loss: 1.0705 - val_accuracy: 0.6750\n",
      "Epoch 100/100\n",
      "57/57 [==============================] - 28s 498ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.5553 - val_accuracy: 0.6050\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train,y_train, validation_data= (x_test,y_test),epochs=100,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYslNPFvpa5K",
    "outputId": "104ca4be-f7d1-4b41-eac6-19e2623e7540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 125ms/step - loss: 2.5553 - accuracy: 0.6050\n",
      "Test Loss: 2.55533504486084\n",
      "Test Accuracy: 60.50000190734863  %\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy*100,\" %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VhGuB-ddpqbN",
    "outputId": "e5ff72e0-5dc2-43cc-ced8-04f21778cfda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 131ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4DUS7kO_oKXI"
   },
   "outputs": [],
   "source": [
    "predictions_label = []\n",
    "for i in range(len(predictions)):\n",
    "    predictions_label.append(predictions[i].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 777
    },
    "id": "F-_k8jdip3_d",
    "outputId": "e9c77c19-cc6c-4eca-9d25-b89e7bb8f2e0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.89      0.68        94\n",
      "         1.0       0.79      0.35      0.48       106\n",
      "\n",
      "    accuracy                           0.60       200\n",
      "   macro avg       0.67      0.62      0.58       200\n",
      "weighted avg       0.68      0.60      0.58       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "cf1 = confusion_matrix(y_test,predictions_label)\n",
    "sns.heatmap(cf1,annot=True,fmt = '.0f')\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix Report')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test,predictions_label))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
