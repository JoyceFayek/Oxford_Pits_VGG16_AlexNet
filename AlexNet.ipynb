{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iUGCkcKmYItU"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "%matplotlib inline \n",
    "from tensorflow import keras\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten ,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam,Nadam, SGD\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "EZpxu855d4E3"
   },
   "outputs": [],
   "source": [
    "cats=[]\n",
    "i=0\n",
    "for images in os.listdir('cats'):\n",
    "    img=cv2.imread((\"cats//\" +images),cv2.IMREAD_UNCHANGED)\n",
    "    if(type(img) == type(None)):\n",
    "      pass\n",
    "    else:\n",
    "      resized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\n",
    "      normalize=(np.asarray(resized).astype('float32')) / 255\n",
    "      cats.append(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "si5nJncfd85F"
   },
   "outputs": [],
   "source": [
    "dogs=[]\n",
    "i=0\n",
    "for images in os.listdir('dogs'):\n",
    "    img=cv2.imread((\"dogs//\" +images),cv2.IMREAD_UNCHANGED)\n",
    "    if(type(img) == type(None)):\n",
    "      pass\n",
    "    else:\n",
    "      resized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\n",
    "      normalize=(np.asarray(resized).astype('float32')) / 255\n",
    "      dogs.append(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "j--3x2pBeAbL"
   },
   "outputs": [],
   "source": [
    "data = cats+dogs\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XopOXHNAlN3H",
    "outputId": "948d8647-31dc-4601-9308-004d589629ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1995, 224, 224, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ZXbfbApseB05"
   },
   "outputs": [],
   "source": [
    "cats_labels = np.ones(len(cats))\n",
    "dogs_labels = np.zeros(len(dogs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIpEYWc7khXH",
    "outputId": "68586d42-34c2-4803-abc8-a457fac80326"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.concatenate((cats_labels, dogs_labels))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "M8JVLQ9FgOAJ"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data,labels,shuffle=True,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3g1PTbZxm72J",
    "outputId": "5031974a-e8dc-4a5b-a470-cd96ea16182b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 224, 224, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3E_fzEMnSZA",
    "outputId": "c948b6f2-674d-440e-9fad-fc597fa29638"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "M3A7Mf3KgV57"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), activation=\"relu\", input_shape=(224, 224, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(3, 3), strides= (2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Qp-iCgZIsmLj"
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbTdvtvEgWD-",
    "outputId": "ef05178b-2107-4fb6-c4b1-b0f0beb08f16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 54, 54, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 54, 54, 96)       384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 26, 26, 96)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 26, 26, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 26, 26, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 12, 12, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 12, 12, 384)       885120    \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 12, 12, 384)      1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 12, 12, 384)       1327488   \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 12, 12, 384)      1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 12, 12, 256)       884992    \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 12, 12, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 5, 5, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4096)              26218496  \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 8194      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46,760,706\n",
      "Trainable params: 46,757,954\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.optimizers.SGD(lr=0.01),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rB68mgaSgwec",
    "outputId": "63641d93-339b-421d-934a-d99154ff6501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "57/57 [==============================] - 4s 54ms/step - loss: 0.0449 - accuracy: 0.9861 - val_loss: 1.9363 - val_accuracy: 0.6400\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 3s 48ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 2.1013 - val_accuracy: 0.6300\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 2.1252 - val_accuracy: 0.6450\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0137 - accuracy: 0.9933 - val_loss: 2.3333 - val_accuracy: 0.6300\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0090 - accuracy: 0.9978 - val_loss: 2.5677 - val_accuracy: 0.6250\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 3s 46ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 2.6170 - val_accuracy: 0.6250\n",
      "Epoch 7/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 2.5598 - val_accuracy: 0.6500\n",
      "Epoch 8/100\n",
      "57/57 [==============================] - 3s 46ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.7649 - val_accuracy: 0.6500\n",
      "Epoch 9/100\n",
      "57/57 [==============================] - 3s 47ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 2.7309 - val_accuracy: 0.6500\n",
      "Epoch 10/100\n",
      "57/57 [==============================] - 3s 49ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 2.7944 - val_accuracy: 0.6450\n",
      "Epoch 11/100\n",
      "57/57 [==============================] - 3s 46ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 2.8537 - val_accuracy: 0.6400\n",
      "Epoch 12/100\n",
      "57/57 [==============================] - 3s 46ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.7687 - val_accuracy: 0.6600\n",
      "Epoch 13/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0071 - accuracy: 0.9972 - val_loss: 2.9280 - val_accuracy: 0.6550\n",
      "Epoch 14/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 3.0614 - val_accuracy: 0.6350\n",
      "Epoch 15/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 3.0607 - val_accuracy: 0.6500\n",
      "Epoch 16/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0121 - accuracy: 0.9978 - val_loss: 3.0072 - val_accuracy: 0.6450\n",
      "Epoch 17/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.0987 - val_accuracy: 0.6550\n",
      "Epoch 18/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0040 - accuracy: 0.9978 - val_loss: 3.1565 - val_accuracy: 0.6400\n",
      "Epoch 19/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 3.1702 - val_accuracy: 0.6450\n",
      "Epoch 20/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 3.1160 - val_accuracy: 0.6550\n",
      "Epoch 21/100\n",
      "57/57 [==============================] - 3s 46ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 3.2654 - val_accuracy: 0.6500\n",
      "Epoch 22/100\n",
      "57/57 [==============================] - 3s 44ms/step - loss: 0.0039 - accuracy: 0.9983 - val_loss: 3.1827 - val_accuracy: 0.6500\n",
      "Epoch 23/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 3.2870 - val_accuracy: 0.6500\n",
      "Epoch 24/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 3.0293 - val_accuracy: 0.6550\n",
      "Epoch 25/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 3.2443 - val_accuracy: 0.6350\n",
      "Epoch 26/100\n",
      "57/57 [==============================] - 3s 44ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 3.4073 - val_accuracy: 0.6300\n",
      "Epoch 27/100\n",
      "57/57 [==============================] - 3s 49ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 2.7468 - val_accuracy: 0.6600\n",
      "Epoch 28/100\n",
      "57/57 [==============================] - 3s 46ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 3.7792 - val_accuracy: 0.6000\n",
      "Epoch 29/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0100 - accuracy: 0.9961 - val_loss: 3.2019 - val_accuracy: 0.6700\n",
      "Epoch 30/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 3.2688 - val_accuracy: 0.6750\n",
      "Epoch 31/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 3.2776 - val_accuracy: 0.6800\n",
      "Epoch 32/100\n",
      "57/57 [==============================] - 3s 44ms/step - loss: 0.0082 - accuracy: 0.9989 - val_loss: 3.2525 - val_accuracy: 0.6800\n",
      "Epoch 33/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 3.4638 - val_accuracy: 0.6200\n",
      "Epoch 34/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 3.2577 - val_accuracy: 0.6600\n",
      "Epoch 35/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 3.0762 - val_accuracy: 0.6600\n",
      "Epoch 36/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 3.2485 - val_accuracy: 0.6500\n",
      "Epoch 37/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 3.2613 - val_accuracy: 0.6400\n",
      "Epoch 38/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 3.2697 - val_accuracy: 0.6400\n",
      "Epoch 39/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 3.3364 - val_accuracy: 0.6400\n",
      "Epoch 40/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.3262 - val_accuracy: 0.6250\n",
      "Epoch 41/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3335 - val_accuracy: 0.6350\n",
      "Epoch 42/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 4.7997 - val_accuracy: 0.5450\n",
      "Epoch 43/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0276 - accuracy: 0.9933 - val_loss: 3.2317 - val_accuracy: 0.6400\n",
      "Epoch 44/100\n",
      "57/57 [==============================] - 3s 47ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 3.0664 - val_accuracy: 0.5950\n",
      "Epoch 45/100\n",
      "57/57 [==============================] - 3s 46ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 2.8080 - val_accuracy: 0.6400\n",
      "Epoch 46/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 2.9911 - val_accuracy: 0.6350\n",
      "Epoch 47/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 4.6564 - val_accuracy: 0.5900\n",
      "Epoch 48/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0271 - accuracy: 0.9889 - val_loss: 3.0724 - val_accuracy: 0.6350\n",
      "Epoch 49/100\n",
      "57/57 [==============================] - 3s 44ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 3.1556 - val_accuracy: 0.6500\n",
      "Epoch 50/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0063 - accuracy: 0.9972 - val_loss: 3.1861 - val_accuracy: 0.6300\n",
      "Epoch 51/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0057 - accuracy: 0.9972 - val_loss: 3.5680 - val_accuracy: 0.6200\n",
      "Epoch 52/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0117 - accuracy: 0.9939 - val_loss: 3.1654 - val_accuracy: 0.6400\n",
      "Epoch 53/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.1861 - val_accuracy: 0.6350\n",
      "Epoch 54/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 3.2405 - val_accuracy: 0.6500\n",
      "Epoch 55/100\n",
      "57/57 [==============================] - 3s 44ms/step - loss: 0.0049 - accuracy: 0.9978 - val_loss: 3.2427 - val_accuracy: 0.6250\n",
      "Epoch 56/100\n",
      "57/57 [==============================] - 3s 44ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 3.4203 - val_accuracy: 0.6450\n",
      "Epoch 57/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 6.0356 - val_accuracy: 0.5650\n",
      "Epoch 58/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 3.7037 - val_accuracy: 0.6150\n",
      "Epoch 59/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 3.5250 - val_accuracy: 0.6300\n",
      "Epoch 60/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 3.4403 - val_accuracy: 0.6400\n",
      "Epoch 61/100\n",
      "57/57 [==============================] - 3s 47ms/step - loss: 5.9492e-04 - accuracy: 1.0000 - val_loss: 3.4522 - val_accuracy: 0.6400\n",
      "Epoch 62/100\n",
      "57/57 [==============================] - 3s 47ms/step - loss: 9.4670e-04 - accuracy: 1.0000 - val_loss: 3.4925 - val_accuracy: 0.6400\n",
      "Epoch 63/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0041 - accuracy: 0.9983 - val_loss: 3.4516 - val_accuracy: 0.6200\n",
      "Epoch 64/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.4957 - val_accuracy: 0.6550\n",
      "Epoch 65/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 3.5298 - val_accuracy: 0.6400\n",
      "Epoch 66/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 3.3830 - val_accuracy: 0.6350\n",
      "Epoch 67/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 3.4055 - val_accuracy: 0.6350\n",
      "Epoch 68/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 8.0123e-04 - accuracy: 1.0000 - val_loss: 3.4469 - val_accuracy: 0.6350\n",
      "Epoch 69/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 3.5064 - val_accuracy: 0.6400\n",
      "Epoch 70/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.5295 - val_accuracy: 0.6450\n",
      "Epoch 71/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 3.5385 - val_accuracy: 0.6250\n",
      "Epoch 72/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0018 - accuracy: 0.9989 - val_loss: 3.6108 - val_accuracy: 0.6600\n",
      "Epoch 73/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 8.1603e-04 - accuracy: 1.0000 - val_loss: 3.6052 - val_accuracy: 0.6450\n",
      "Epoch 74/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 3.6188 - val_accuracy: 0.6500\n",
      "Epoch 75/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.6946 - val_accuracy: 0.6350\n",
      "Epoch 76/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0014 - accuracy: 0.9989 - val_loss: 3.4983 - val_accuracy: 0.6450\n",
      "Epoch 77/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 2.7854 - val_accuracy: 0.6250\n",
      "Epoch 78/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 3.0390 - val_accuracy: 0.6550\n",
      "Epoch 79/100\n",
      "57/57 [==============================] - 3s 48ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 3.2103 - val_accuracy: 0.6500\n",
      "Epoch 80/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 3.3140 - val_accuracy: 0.6550\n",
      "Epoch 81/100\n",
      "57/57 [==============================] - 3s 46ms/step - loss: 0.0071 - accuracy: 0.9994 - val_loss: 3.5434 - val_accuracy: 0.5950\n",
      "Epoch 82/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0116 - accuracy: 0.9955 - val_loss: 2.8908 - val_accuracy: 0.6300\n",
      "Epoch 83/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 2.9363 - val_accuracy: 0.6450\n",
      "Epoch 84/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 3.0725 - val_accuracy: 0.6550\n",
      "Epoch 85/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 3.1086 - val_accuracy: 0.6500\n",
      "Epoch 86/100\n",
      "57/57 [==============================] - 3s 48ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 3.0288 - val_accuracy: 0.6350\n",
      "Epoch 87/100\n",
      "57/57 [==============================] - 3s 46ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 2.9932 - val_accuracy: 0.6150\n",
      "Epoch 88/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 3.0207 - val_accuracy: 0.6400\n",
      "Epoch 89/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 3.1152 - val_accuracy: 0.6200\n",
      "Epoch 90/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 2.2418 - val_accuracy: 0.6300\n",
      "Epoch 91/100\n",
      "57/57 [==============================] - 3s 44ms/step - loss: 0.0236 - accuracy: 0.9950 - val_loss: 2.9666 - val_accuracy: 0.5850\n",
      "Epoch 92/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0398 - accuracy: 0.9922 - val_loss: 2.5667 - val_accuracy: 0.6200\n",
      "Epoch 93/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0078 - accuracy: 0.9967 - val_loss: 2.5846 - val_accuracy: 0.6350\n",
      "Epoch 94/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 2.6346 - val_accuracy: 0.6150\n",
      "Epoch 95/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 2.6836 - val_accuracy: 0.6350\n",
      "Epoch 96/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.7879 - val_accuracy: 0.6400\n",
      "Epoch 97/100\n",
      "57/57 [==============================] - 3s 46ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 2.8597 - val_accuracy: 0.6450\n",
      "Epoch 98/100\n",
      "57/57 [==============================] - 3s 48ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.9049 - val_accuracy: 0.6550\n",
      "Epoch 99/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.9546 - val_accuracy: 0.6450\n",
      "Epoch 100/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.0390 - val_accuracy: 0.6550\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train,y_train, validation_data= (x_test,y_test),epochs=100,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYslNPFvpa5K",
    "outputId": "70ab54e7-54c5-45cc-a836-43c253555a98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 24ms/step - loss: 3.0390 - accuracy: 0.6550\n",
      "Test Loss: 3.038973093032837\n",
      "Test Accuracy: 65.49999713897705  %\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy*100,\" %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VhGuB-ddpqbN",
    "outputId": "88ebd5bb-fdae-42f8-f53e-96031194c6c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "4DUS7kO_oKXI"
   },
   "outputs": [],
   "source": [
    "predictions_label = []\n",
    "for i in range(len(predictions)):\n",
    "    predictions_label.append(predictions[i].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 777
    },
    "id": "F-_k8jdip3_d",
    "outputId": "693b41de-90fe-4aef-dfd1-514531aab85e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.59      0.64       105\n",
      "         1.0       0.62      0.73      0.67        95\n",
      "\n",
      "    accuracy                           0.66       200\n",
      "   macro avg       0.66      0.66      0.65       200\n",
      "weighted avg       0.66      0.66      0.65       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "cf1 = confusion_matrix(y_test,predictions_label)\n",
    "sns.heatmap(cf1,annot=True,fmt = '.0f')\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix Report')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test,predictions_label))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
